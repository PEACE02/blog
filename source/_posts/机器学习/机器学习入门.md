---
title: 机器学习入门 | Python 数理统计编程
date: 2022-10-08
katex: true
categories:
- 机器学习
tags: 
- 数学
- 数理统计
keywords: 
- 机器学习入门
- 数理统计
- 平均中位数模式
- 标准差
- 百分位数
- 数据分布
- 正态数据分布
- 散点图
- 线性回归
- 多项式回归
- 多元回归
- 缩放
- 训练/测试
- 决策树
description: 内容参考：W3school，意在记录学习过程，加深印象。
cover: https://s2.loli.net/2022/10/08/r9fP6xFcUNYDwVn.jpg
---

本文内容参考：[W3school](https://www.w3school.com.cn/python/python_ml_getting_started.asp)，意在记录学习过程，加深印象。

---

# 数据集和数据类型
机器学习是一种程序，使计算机能够从研究数据和统计信息中学习，可以**分析数据**并学习**预测结果**。

## 数据集
数据集指**任何数据集合**，可以是从数组到完整数据库的任何内容。

## 数据类型
三种主要类别：
- **数值 (Numerical)**
  数字，可以分为 **离散数据 (Discrete Data)** 和 **连续数据 (Continuous Data)** 。
- **分类 (Categorical)**
  无法相互度量的值，如颜色值或任何 yes/no 值。
- **序数 (Ordinal)**
  类似于分类数据，但可以相互度量，如 A 优于 B 的学校成绩，依次类推。

---

# 平均中位数模式
在机器学习（和数学）中，我们通常考虑：**均值 (Mean) 、中值 (Median) 、众数 (Mode)**

例如，我们登记了 13 辆车的速度：`speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]`

## 均值
使用 NumPy `mean()` 方法求均值。

```python
import numpy
speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = numpy.mean(speed)
print(x)
```

## 中值
对所有值进行**排序后**的中间值，如果中间有两个数字，求两数均值。
使用 NumPy `median()` 方法求中值。

```python
import numpy
speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = numpy.median(speed)
print(x)
```

## 众数
使用 SciPy `mode()` 方法查找出现次数最多的数字。

```python
from scipy import stats
speed = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]
x = stats.mode(speed)
print(x)
```

---

# 方差、标准差
## 方差
一个数字，指示值的分散程度，用符号 $\sigma^2$ 表示。方差公式：$\sigma^2\;=\;\frac1n\sum_{i=1}^n{(\overline x-x_i)}^2$

使用 NumPy `var()` 方法求方差。

```python
import numpy
speed = [86, 87, 88, 86, 87, 85, 86]
x = numpy.var(speed)
print(x)
```

## 标准差
标准差 (Standard Deviation) ，又称均方差，用符号 $\sigma$ 表示。方差的平方根，描述值的离散程度。
低标准偏差表示大多数数字接近均值，高标准偏差表示这些值分布在更宽的范围内。

使用 NumPy `std()` 方法求标准差。

```python
import numpy
speed = [86, 87, 88, 86, 87, 85, 86]
x = numpy.std(speed)
print(x)
```
`Output: 0.9` ，意味着大多数值在平均值的 0.9 范围内。

`speed = [32,111,138,28,59,77,97]`
`Output: 37.85` ，这意味着大多数值在平均值 (77.4) 的 37.85 范围内。

---

# 百分位数
统计学中使用百分位数 (Percentiles) 提供一个数字，该数字描述了给定百分比值小于的值。

例如，假设有一个数组，包含住在一条街上的人的年龄。
`ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]`
75 百分位数是 43 ，这意味着 75% 的人是 43 岁或以下。

使用 NumPy `percentile()` 方法查找百分位数。

```python
import python
ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]
x = numpy.percentile(ages, 75)
print(x)
```

---

# 数据分布
为了创建用于测试的大数据集，使用 NumPy 模块，其附带了许多创建任意大小的随机数据集的方法。

创建一个包含 250 个介于 0 ~ 5 之间的随机浮点数的数组。

```python
import numpy
x = numpy.random.uniform(0.0, 5.0, 250)
print(x)
```

## 直方图
为了可视化数据集，可以对收集的数据绘制直方图。

使用 Matplotlib 绘制直方图。

```python
import numpy
import matplotlib.pyplot as plt
x = numpy.random.uniform(0.0, 5.0, 250)
plt.hist(x, 5)
plt.show()
```
## 正态数据分布
在概率论中，在数学家卡尔·弗里德里希·高斯（Carl Friedrich Gauss）提出了这种数据分布的公式之后，这种数据分布被称为正态数据分布或高斯数据分布。

典型的正态数据分布：
```python
import numpy
import matplotlib as plt
x = numpy.random.normal(5.0, 1.0, 100000)
plt.hist(x, 100)
plt.show()
```
![](https://www.w3school.com.cn/i/python/img_numpy_normal_1.png)
由于正态分布图具有钟形的特征形状，因此也称为钟形曲线。

### 直方图解释
使用 `numpy.random.normal()` 方法创建的数组（具有 100000 个值）绘制具有 100 栏的直方图。
我们指定平均值为 5.0 ，标准差为 1.0 。这意味着这些值应集中在 5.0 左右，并且很少与平均值偏离 1.0 。
从直方图中可以看到，大多数值都在 4.0 ~ 6.0 之间，最多的值大约是 5.0 。

---

# 散点图
Matplotlib 模块有一种绘制散点图的方法，它需要两个长度相同的数组，分别用于 x 轴和 y 轴。

创建两个数组，它们都填充有来自正态数据分布的 1000 个随机数。第一个数组的平均值设置为 5.0 ，标准差为 1.0 ；第二个数组的平均值设置为 10.0 ，标准差为 2.0 。

使用 `scatter()` 方法绘制有 1000 个点的散点图。

```python
import numpy
import matplotlib.pyplot as plt
x = numpy.random.normal(5.0, 1.0, 1000)
y = numpy.random.normal(10.0, 2.0, 1000)
plt.scatter(x, y)
plt.show()
```
![](https://www.w3school.com.cn/i/python/img_matplotlib_scatter_1000.png)

---

# 线性回归
当尝试找到变量之间的关系时，会用到术语“回归”(regression)。在机器学习和统计建模中，这种关系用于预测未来事件的结果。

线性回归使用数据点之间的关系在所有数据点之间画一条直线，这条线可以用来预测未来的值。在机器学习中，预测未来非常重要。

首先绘制散点图，然后导入 `scipy` 并绘制线性回归线。

```python
import matplotlib.pyplot as plt
from scipy import stats
# 创建表示 x 和 y 轴值的数组
x = [5,7,8,7,2,17,2,9,4,11,12,9,6]
y = [99,86,87,88,111,86,103,87,94,78,77,85,86]
# 执行一个方法，该方法返回线性回归的一些重要键值
# 斜率、截距、r^2、p值（p检验的统计量）、标准差
slope, intercept, r, p, std_err = stats.linregress(x, y)
# 创建一个使用 slope 和 intercept 值的函数返回新值。
# 这个新值表示相应的 x 值将在 y 轴上放置的位置：
def myfunc(x):
    return slope * x + intercept
# 通过函数运行 x 数组的每个值。
# 这将产生一个新的数组，其中的 y 轴具有新值：
mymodel = list(map(myfunc, x))
# 绘制原始散点图：
plt.scatter(x, y)
# 绘制线性回归线：
plt.plot(x, mymodel)
plt.show()
```
![](https://www.w3school.com.cn/i/python/img_linear_regression_2.png)

## R-Squared
x 和 y 轴的值之间的相关性用一个称为 $r^2$ 的值来度量。其值范围 0 ~ 1 ，0 表示不相关，1 表示 100% 相关。（正负表示正相关或负相关）如果得到了一个非常小的，接近 0 的 r-squared 值，这说明该数据集不适合线性回归。

---

# 多项式回归
如果数据集不适合线性回归，那么多项式回归 (Ploynomial Regression) 可能是理想的选择。像线性回归一样，多项式回归使用变量 x 和 y 之间的关系来找到绘制数据点线的最佳方法。

首先绘制散点图，然后画出多项式回归线。

```python
import numpy
import matplotlib.pyplot as plt

x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]
y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]
# NumPy 有一种方法可以让我们建立多项式模型：
mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))
# 然后指定行的显示方式，我们从位置 1 开始，到位置 22 结束：
myline = numpy.linspace(1, 22, 100)

plt.scatter(x, y)
plt.plot(myline, mymodel(myline))
plt.show()
```
![](https://www.w3school.com.cn/i/python/img_polynomial_regression.png)

## R-Squared
同样的，多项式回归也有相关性度量。我们可以用 Sklearn 模块计算 $r^2$ 的值。

```python
import numpy
import sklearn.metrics import r2_score

x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]
y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]

mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))
print(r2_score(y, mymodel(x)))
```
结果 0.94 表明存在很好的关系，我们可以在将来的预测中使用多项式回归。如果得到了一个非常小的，接近 0 的 r-squared 值，这说明该数据集不适合多项式回归。

---

# 多元回归
多元回归 (Multiple Regression) 就像线性回归一样，但是具有多个独立值，这意味着我们试图基于两个或多个变量来预测一个值。下面的数据集包含了一些有关汽车的信息。
| Car        | Model      | Volume | Weight | CO2 |
|------------|------------|--------|--------|-----|
| Toyota     | Aygo       | 1000   | 790    | 99  |
| Mitsubishi | Space Star | 1200   | 1160   | 95  |
| Skoda      | Citigo     | 1000   | 929    | 95  |
| Fiat       | 500        | 900    | 865    | 90  |
| Mini       | Cooper     | 1500   | 1140   | 105 |
| VW         | Up!        | 1000   | 929    | 105 |
| Skoda      | Fabia      | 1400   | 1109   | 90  |
| Mercedes   | A-Class    | 1500   | 1365   | 92  |
| Ford       | Fiesta     | 1500   | 1112   | 98  |
| Audi       | A1         | 1600   | 1150   | 99  |
| Hyundai    | I20        | 1100   | 980    | 99  |
| Suzuki     | Swift      | 1300   | 990    | 101 |
| Ford       | Fiesta     | 1000   | 1112   | 99  |
| Honda      | Civic      | 1600   | 1252   | 94  |
| Hundai     | I30        | 1600   | 1326   | 97  |
| Opel       | Astra      | 1600   | 1330   | 97  |
| BMW        | 1          | 1600   | 1365   | 99  |
| Mazda      | 3          | 2200   | 1280   | 104 |
| Skoda      | Rapid      | 1600   | 1119   | 104 |
| Ford       | Focus      | 2000   | 1328   | 105 |
| Ford       | Mondeo     | 1600   | 1584   | 94  |
| Opel       | Insignia   | 2000   | 1428   | 99  |
| Mercedes   | C-Class    | 2100   | 1365   | 99  |
| Skoda      | Octavia    | 1600   | 1415   | 99  |
| Volvo      | S60        | 2000   | 1415   | 99  |
| Mercedes   | CLA        | 1500   | 1465   | 102 |
| Audi       | A4         | 2000   | 1490   | 104 |
| Audi       | A6         | 2000   | 1725   | 114 |
| Volvo      | V70        | 1600   | 1523   | 109 |
| BMW        | 5          | 2000   | 1705   | 114 |
| Mercedes   | E-Class    | 2100   | 1605   | 115 |
| Volvo      | XC70       | 2000   | 1746   | 117 |
| Ford       | B-Max      | 1600   | 1235   | 104 |
| BMW        | 2          | 1600   | 1390   | 108 |
| Opel       | Zafira     | 1600   | 1405   | 109 |
| Mercedes   | SLK        | 2500   | 1395   | 120 |

我们可以根据发动机的大小预测汽车的二氧化碳排放量，但是通过多元回归，我们可以引入更多变量，例如汽车的重量，以使预测更加准确。这里是用到的数据集，可以点击下载：[cars.csv](https://www.w3school.com.cn/python/cars.csv)

使用 Pandas 模块读取 csv 文件，取出独立值和相关值列表。在 sklearn 模块中使用 `LinearRegreesion()` 方法创建一个线性回归对象，该对象有一个 `fit()` 方法，将独立值和从属值作为参数，并用描述这种关系的数据填充回归对象。有了回归对象，就可以根据汽车的重量和排量预测 CO2 的值。

```python
import pandas
from sklearn import linear_model

df = pandas.read_csv('cars.csv')

X = df[['Weight', 'Volume']]
y = df['CO2']

regr = linear_model.LinearRegession()
regr.fit(X, y)

# 预测重量为 2300kg、排量为 1300ccm 的汽车的二氧化碳排放量：
predictedCO2 = regr.predict([[2300, 1300]])
print(predictCO2)
```

输出结果为 `[107.2087328]` ，我们可以预测，配备 1.3 升发动机，重量为 2300kg 的汽车，每行驶 1 公里，就会释放约 107g 二氧化碳。

## 系数
系数是描述与未知变量的关系的因子。例如 `2x` ，`x` 是未知变量，`2` 是系数。

我们可以求得重量相对于 CO2 的系数值，以及体积相对于 CO2 的系数值。打印回归对象的系数值：
```python
import pandas
from sklearn import linear_model

df = pandas.read_csv('cars.csv')

X = df[['Weight', 'Volume']]
y = df['CO2']

regr = linear_model.LinearRegession()
regr.fit(X, y)

print(regr.coef_)
```

输出结果为 `[0.00755095 0.00780526]` ，分别表示重量和排量的系数值。
我们可以猜测，如果重量增加 1g，则 CO2 排放量将增加 0.00755095g。
如果发动机尺寸（容积）增加 1 ccm，则 CO2 排放量将增加 0.00780526g。

可以复制之前的例子，但是将车重从 2300 更改为 3300 ，以此验证我们的猜想。
即有 `predictedCO2 = regr.predict([[3300, 1300]])` ，输出结果为 `[114.75968007]` 。
而 `107.2087328 + (1000 * 0.00755095) = 114.75968` ，这表明我们对系数的猜想是正确的。

---

# 缩放
当数据拥有不同的值甚至不同的度量单位时，可能很难比较它们。我们可以将数据缩放为易于比较的新值。

下表与多元回归中使用的数据集相同，不过 Volume 列的单位是升，而不是 ccm (1.0 而不是 1000) 。
| Car        | Model      | Volume | Weight | CO2 |
|------------|------------|--------|--------|-----|
| Toyota     | Aygo       | 1.0    | 790    | 99  |
| Mitsubishi | Space Star | 1.2    | 1160   | 95  |
| Skoda      | Citigo     | 1.0    | 929    | 95  |
| Fiat       | 500        | 0.9    | 865    | 90  |
| Mini       | Cooper     | 1.5    | 1140   | 105 |
| VW         | Up!        | 1.0    | 929    | 105 |
| Skoda      | Fabia      | 1.4    | 1109   | 90  |
| Mercedes   | A-Class    | 1.5    | 1365   | 92  |
| Ford       | Fiesta     | 1.5    | 1112   | 98  |
| Audi       | A1         | 1.6    | 1150   | 99  |
| Hyundai    | I20        | 1.1    | 980    | 99  |
| Suzuki     | Swift      | 1.3    | 990    | 101 |
| Ford       | Fiesta     | 1.0    | 1112   | 99  |
| Honda      | Civic      | 1.6    | 1252   | 94  |
| Hundai     | I30        | 1.6    | 1326   | 97  |
| Opel       | Astra      | 1.6    | 1330   | 97  |
| BMW        | 1          | 1.6    | 1365   | 99  |
| Mazda      | 3          | 2.2    | 1280   | 104 |
| Skoda      | Rapid      | 1.6    | 1119   | 104 |
| Ford       | Focus      | 2.0    | 1328   | 105 |
| Ford       | Mondeo     | 1.6    | 1584   | 94  |
| Opel       | Insignia   | 2.0    | 1428   | 99  |
| Mercedes   | C-Class    | 2.1    | 1365   | 99  |
| Skoda      | Octavia    | 1.6    | 1415   | 99  |
| Volvo      | S60        | 2.0    | 1415   | 99  |
| Mercedes   | CLA        | 1.5    | 1465   | 102 |
| Audi       | A4         | 2.0    | 1490   | 104 |
| Audi       | A6         | 2.0    | 1725   | 114 |
| Volvo      | V70        | 1.7    | 1523   | 109 |
| BMW        | 5          | 2.0    | 1705   | 114 |
| Mercedes   | E-Class    | 2.1    | 1605   | 115 |
| Volvo      | XC70       | 2.0    | 1746   | 117 |
| Ford       | B-Max      | 1.6    | 1235   | 104 |
| BMW        | 2          | 1.6    | 1390   | 108 |
| Opel       | Zafira     | 1.6    | 1405   | 109 |
| Mercedes   | SLK        | 2.5    | 1395   | 120 |
很难将排量 1.0 与车重 790 进行比较，因此需要将它们都缩放为可比较的值以进行比较。

## 特征缩放
缩放数据有很多方法，此处使用一种称为 **标准化 (Standardization)** 的方法。
标准化公式： $z = (x - u) / s$ ，其中 z 是新值，x 是原始值，u 是平均值，s 是标准差。

从上面数据集中获取 weight 列，第一个值为 790 ，缩放后的值为：
`-2.1 = (790 - 1292.23) / 238.4`

从上面数据集中获取 volume 列，第一个值为 1.0 ，缩放后的值为：
`-1.59 = (1.0 - 1.61) / 0.38`

现在可以将 -2.1 和 -1.59 相比较，而不是比较 790 和 1.0 。

## StandardScaler()
Python sklearn 模块有一个名为 `StandardScaler()` 方法，还方法返回带有转换数据集方法的 Scaler 对象。

缩放 Weight 和 Volume 列中的所有值：

```python
import pandas as pd
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler

scale = StandardScaler()
df = pd.read_csv('cars2.csv')
X = df[['Weight', 'Volume']]
scaledX = scale.fit_transfrom(X)
print(scaledX)
```

结果如下，前两个值是 -2.1 和 -1.59 ，与我们的计算一致：
`[[-2.10389253 -1.59336644], ... (此处省略)]`

## 预测 CO2 的值
缩放数据集后，在预测值时必须使用缩放比例。

预测一辆重 2300 公斤，排量 1.3 升的汽车的二氧化碳排放量：

```python
import pandas as pd
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler

scale = StandardScaler()

df = pd.read_csv('cars2.csv')
X = df[['Weight', 'Volume']]
y = df['CO2']
scaledX = scale.fit_transfrom(X)

regr = linear_model.LinearRegression()
regr.fit(scaledX, y)
scaled = scale.transfrom([2300, 1.3])
predictedCO2 = regr.predict([scaled[0]])
print(predictedCO2)
```

结果：`[107.2087328]`，与多元回归中预测结果一致。

---

# 训练/测试
在机器学习中，我们创建模型来预测某些事件的结果。要衡量模型是否足够好，我们可以使用一种称为 训练/测试 的方法。

训练/测试 是一种测量模型准确性的方法，将数据集分为 训练集 和 测试集 。使用训练集训练模型意味着创建模型，使用测试集测试模型意味着测试模型的准确性。

## 从数据集开始
生成随机数据，模拟展示商店中的 100 位顾客及其购物习惯。

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(2)
x = np.random.noraml(3, 1, 100)
y = np.random.normal(150, 40, 100) / x

plt.scatter(x, y)
plt.show()
```

x 轴表示购买前的分钟数，y 轴表示在购买上花费的金额。

![](https://www.w3school.com.cn/i/python/img_traintest_1.png)

## 拆分训练/测试
我们以原始数据中的 80% 作为训练集，剩余的 20% 作为测试集。
```python
# 结合上面代码
train_x = x[:80]
train_y = y[:80]
test_x = x[80:]
test_y = y[80:]
# 显示训练集散点图
plt.scatter(train_x, train_y)
plt.show()
# 显示测试集散点图
plt.scatter(test_x, test_y)
plt.show()
```
训练集看起来与原始数据集相似，因此似乎是一个合理的选择。
![](https://www.w3school.com.cn/i/python/img_traintest_2.png)

测试集看起来也像原始数据集。
![](https://www.w3school.com.cn/i/python/img_traintest_3.png)

## 拟合数据集
由散点图判断最适合拟合的是多项式回归。
```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(2)
x = np.random.normal(3, 1, 100)
y = np.random.normal(150, 40, 100) / x
train_x = x[:80]
train_y = y[:80]
test_x = x[80:]
test_y = y[80:]

mymodel = np.poly1d(np.polyfit(train_x, train_y, 4))
myline = np.linspace(0, 6, 100)

plt.scatter(train_x, train_y)
plt.plot(myline, mymodel(myline))
plt.show()
```

此结果可以支持我们对数据集拟合多项式回归的建议，即使如果我们尝试预测数据集之外的值会给我们带来一些奇怪的结果。例如，该拟合曲线表明某位顾客在商店购物 6 分钟，会完成一笔价值 200 的购物，这可能是过拟合的迹象。
![](https://www.w3school.com.cn/i/python/img_traintest_4.png)

## R-squared
R-squared score 可以很好地指示我们数据集对模型的拟合程度。

我们来衡量一下顾客在商店停留的时间与他们花费多少钱之间的关系。

```python
import numpy as np
from sklearn.metrics import re_score

np.random.seed(2)
x = np.random.normal(3, 1, 100)
y = np.random.normal(150, 40, 100) / x

train_x = x[:80]
train_y = y[:80]
test_x = x[80:]
test_x = x[80:]

mymodel = np.ploy1d(np.polyfit(train_x, train_y, 4))
train_r2 = r2_score(train_y, mymodel(train_x))
test_r2 = r2_score(test_y, mymodel(test_x))
print(train_r2)
print(test_r2)
```
训练集结果 `0.799` 显示关系不错。测试集结果 `0.809` 表明该模型也适合测试集，我们确信可以使用该模型预测未来值。

## 预测值
现在已经确定了我们的模型是不错的，可以开始预测新值了。
例如预测：如果购买客户在商店停留 5 分钟，Ta将花费多少钱？
`print(mymodel(5))`

---

# 决策树
![](https://www.w3school.com.cn/i/python/img_ml_decision_tree.png)
决策树 (Decision Tree) 是一种流程图，可以根据以前的经验进行决策。

在本节例子中，一个人将尝试决定Ta是否应该参加喜剧节目。如下表，Ta每次在镇上举办喜剧节目时都注册了一些关于戏剧演员的信息，并且登记了Ta是否参加。
| Age | Experience | Rank | Nationality | Go  |
|-----|------------|------|-------------|-----|
| 36  | 10         | 9    | UK          | NO  |
| 42  | 12         | 4    | USA         | NO  |
| 23  | 4          | 6    | N           | NO  |
| 52  | 4          | 4    | USA         | NO  |
| 43  | 21         | 8    | USA         | YES |
| 44  | 14         | 5    | UK          | NO  |
| 66  | 3          | 7    | N           | YES |
| 35  | 14         | 9    | UK          | YES |
| 52  | 13         | 7    | N           | YES |
| 35  | 5          | 9    | N           | YES |
| 24  | 3          | 5    | USA         | NO  |
| 18  | 3          | 7    | UK          | YES |
| 45  | 9          | 9    | UK          | YES |
现在，基于此数据集，我们可以使用 Python 创建决策树，这个决策树可用于决定是否值得参加任何新的演出。

## 工作原理
首先，读取并打印数据集。

如需制作决策树，所有数据都必须是数字。我们必须将非数字列 `Nationality` 和 `Go` 转换为数值。

Pandas 有一个 `map()` 方法，该方法接受字典，其中包含有关如何转换值的信息。

例如：`{'UK': 0, 'USA': 1, 'N': 2}` ，表示值与数字的转换关系。

然后，我们必须将特征列与目标列分开。特征列是我们尝试从中预测的列，目标列是具有我们尝试预测的值的列。

现在，我们可以创建实际的决策树，然后在计算机上保存一个 png 图片。

```python
import pandas as pd
from sklearn import tree
import pydotplus
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
import matplotlib.image as pltimg

# 读取并打印数据集
df = pd.read_csv('shows.csv')
print(df)

# 数据转换
d = {'UK': 0, 'USA': 1, 'N': 2}
df['Nationality'] = df['Nationality'].map(d)
d = {'YES': 1, 'NO': 0}
df['GO'] = df['GO'].map(d)
print(df)

# X 是特征列，y 是目标列
features = ['Age', 'Experience', 'Rank', 'Nationality']
X = df[features]
y = df['GO']
print(X)
print(y)

# 创建一个决策树，另存为图像并显示
dtree = DecisionTreeClassifiter()
dtree = dtree.fit(X, y)
data = tree.export_graphviz(dtree, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(data)
graph.write_png('mydecisiontree.png')

img = pltimg.imread('mydecisiontree.png')
implot = plt.imshow(img)
plt.show()
```

## 结果解释
![](https://www.w3school.com.cn/i/python/img_decisiontree_1.png)
- Rank
  `Rank <= 6.5` 表示排名在 6.5 以下的喜剧演员将遵循 `True` 箭头，其余则遵循 `False` 箭头。
- Gini
  `gini = 0.497` 表示分割的质量，并且始终是 0.0 ~ 0.5 的数字，其中 0.0 表示所有样本均得到相同的结果，而 0.5 表示完全均等分割。
  
- Samples
  `samples = 13` 表示在该决策点上还剩 13 位喜剧演员。
- Value
  `value = [6, 7]` 表示在这 13 位喜剧演员中，有 6 位将获得 "NO"，而 7 位将获得 "YES"。

### Gini
使用 GINI 方法分割样本。公式：$Gini = 1 - (x / n)^2 - (y / n)^2$
其中，x 是肯定答案 YES 的数量，n 是样本 ('GO') 数量，y 是否定答案 NO 的数量。

第一个节点使用公式计算得：$1 - (7 / 13)^2 - (6 / 13)^2 = 0.497$

而 `gini = 0.0` 表示所有样本都得到相同的结果，分支到此结束。

## 预测值
尝试预测：是否应该去看一个由 40 岁的美国喜剧演员主演的节目，该喜剧演员有十年经验，喜剧排名为 7 。
使用 `predict()` 方法来预测新值：
`print(dtree.predict([40, 10, 7, 1]))`

如果运行足够多次，即使输入的数据相同，决策树也会提供不同的结果。这是因为决策树无法给我们 100% 的肯定答案，它基于结果的可能性，答案会有所不同。


_**——OVER.**_